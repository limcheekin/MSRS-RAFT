{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ RAFT Fine-tuning on MSRS Story-QA\n",
        "\n",
        "Complete pipeline for fine-tuning Qwen3-4B-Instruct with RAFT methodology on Google Colab T4 GPU.\n",
        "\n",
        "## üìã What This Notebook Does\n",
        "\n",
        "1. **Setup Environment** - Install dependencies and clone repository\n",
        "2. **Load Data** - Download MSRS Story-QA dataset\n",
        "3. **Build Index** - Create vector search index\n",
        "4. **Generate RAFT Dataset** - Create training data with CoT and citations\n",
        "5. **Train Model** - Fine-tune with Unsloth QLoRA\n",
        "6. **Evaluate** - Test model performance\n",
        "\n",
        "## ‚öôÔ∏è Requirements\n",
        "\n",
        "- **GPU**: T4 (15GB VRAM)\n",
        "- **RAM**: High-RAM runtime recommended\n",
        "- **Time**: ~3-4 hours for 50-100 training examples\n",
        "- **API Key**: OpenAI API key for CoT generation\n",
        "\n",
        "## üéØ Quick Start\n",
        "\n",
        "1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
        "2. Run all cells in order\n",
        "3. Enter your OpenAI API key when prompted\n",
        "4. Wait for training to complete\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîß Step 1: Setup Environment\n",
        "\n",
        "Install all required packages and clone the repository."
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Install PyTorch with CUDA support\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "id": "install_pytorch"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Clone the repository\n",
        "!git clone https://github.com/limcheekin/MSRS-RAFT.git\n",
        "%cd MSRS-RAFT"
      ],
      "metadata": {
        "id": "clone_repo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Install all dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Upgrade Unsloth to latest\n",
        "!pip install --upgrade --force-reinstall --no-cache-dir unsloth unsloth_zoo\n",
        "\n",
        "# Download NLTK data\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)"
      ],
      "metadata": {
        "id": "install_deps"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify installation\n",
        "print(\"üîç Verifying installation...\\n\")\n",
        "!python test_installation.py"
      ],
      "metadata": {
        "id": "verify_install",
        "outputId": "410556bf-752e-473e-ca44-9e99f1255dc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Verifying installation...\n",
            "\n",
            "INFO: ======================================================================\n",
            "INFO: RAFT Installation Test\n",
            "INFO: ======================================================================\n",
            "INFO: \n",
            "Running tests...\n",
            "\n",
            "INFO: ‚úì Python Version: Python 3.12.12\n",
            "INFO: ‚úì PyTorch: torch\n",
            "INFO: ‚úì CUDA Support: CUDA 12.8 - Tesla T4\n",
            "INFO: ‚úì Transformers: Transformers 4.56.2\n",
            "INFO: ‚úì Accelerate: accelerate\n",
            "INFO: NumExpr defaulting to 2 threads.\n",
            "2025-10-21 02:41:15.708498: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761014476.056438    2402 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761014476.151779    2402 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761014476.860394    2402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761014476.860442    2402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761014476.860451    2402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761014476.860458    2402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-21 02:41:16.927877: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "INFO: ‚úì PEFT: peft\n",
            "INFO: ‚úì BitsAndBytes: bitsandbytes\n",
            "/content/MSRS-RAFT/test_installation.py:51: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastLanguageModel\n",
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "INFO: TensorFlow version 2.19.0 available.\n",
            "INFO: JAX version 0.5.3 available.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO: ‚úì Unsloth: Unsloth\n",
            "INFO: ‚úì TRL: trl\n",
            "INFO: ‚úì Datasets: datasets\n",
            "INFO: ‚úì Sentence Transformers: Sentence Transformers\n",
            "INFO: Loading faiss with AVX2 support.\n",
            "INFO: Successfully loaded faiss with AVX2 support.\n",
            "INFO: ‚úì FAISS: FAISS\n",
            "INFO: ‚úì ROUGE Score: rouge_score\n",
            "INFO: ‚úì BERTScore: bert_score\n",
            "INFO: ‚úì NLTK: nltk\n",
            "INFO: ‚úì NLTK Data: NLTK (punkt tokenizer)\n",
            "INFO: ‚úì OpenAI: openai\n",
            "WARNING: ‚ö† OpenAI API Key: OPENAI_API_KEY not set (required for CoT generation)\n",
            "INFO: ‚úì NumPy: numpy\n",
            "INFO: ‚úì Pandas: pandas\n",
            "INFO: ‚úì TQDM: tqdm\n",
            "INFO: ‚úì YAML: PyYAML\n",
            "INFO: ‚úì Project Modules: All project modules\n",
            "INFO: \n",
            "======================================================================\n",
            "INFO: TEST SUMMARY\n",
            "INFO: ======================================================================\n",
            "INFO: Passed:   22/23\n",
            "INFO: Failed:   0/23\n",
            "INFO: Warnings: 1/23\n",
            "INFO: \n",
            "======================================================================\n",
            "INFO: WARNINGS (Non-Critical)\n",
            "INFO: ======================================================================\n",
            "INFO: \n",
            "OpenAI API Key:\n",
            "INFO:   OPENAI_API_KEY not set (required for CoT generation)\n",
            "INFO:   Note: Required only for RAFT dataset generation (CoT creation)\n",
            "INFO:   Set with: export OPENAI_API_KEY='your-key-here'\n",
            "INFO: \n",
            "======================================================================\n",
            "INFO: ‚úì Installation Complete - Ready to run!\n",
            "INFO: \n",
            "Next steps:\n",
            "INFO:   1. Review configuration: python raft_config.py\n",
            "INFO:   2. Run quick test: python example_usage.py 1\n",
            "INFO:   3. Run full pipeline: python raft_pipeline.py --step all\n",
            "INFO: ======================================================================\n",
            "INFO: \n",
            "======================================================================\n",
            "INFO: QUICK FUNCTIONALITY TEST\n",
            "INFO: ======================================================================\n",
            "INFO: \n",
            "1. Testing configuration...\n",
            "INFO:    ‚úì Configuration module works\n",
            "INFO: \n",
            "2. Testing data structures...\n",
            "INFO:    ‚úì Data structures work\n",
            "INFO: \n",
            "3. Testing retrieval components...\n",
            "INFO: Initialized chunker: size=100, overlap=20\n",
            "INFO:    ‚úì Retrieval components work\n",
            "INFO: \n",
            "4. Testing evaluation components...\n",
            "INFO:    ‚úì Evaluation components work\n",
            "INFO: \n",
            "‚úì All core functionality tests passed!\n",
            "INFO: \n",
            "GPU 0: Tesla T4\n",
            "INFO:   Total Memory: 14.74 GB\n",
            "WARNING:   ‚ö† Less than 16GB - may need to reduce batch size\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîë Step 2: Configure API Keys and Settings\n",
        "\n",
        "Set up your OpenAI API key and configure training parameters."
      ],
      "metadata": {
        "id": "config_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Get OpenAI API key\n",
        "print(\"üìù Enter your OpenAI API key (required for RAFT dataset generation):\")\n",
        "openai_key = getpass(\"OpenAI API Key: \")\n",
        "os.environ['OPENAI_API_KEY'] = openai_key\n",
        "\n",
        "print(\"\\n‚úÖ API key configured!\")"
      ],
      "metadata": {
        "id": "set_api_key",
        "outputId": "dfd8773a-5535-43b9-e0cd-87782cef6dc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìù Enter your OpenAI API key (required for RAFT dataset generation):\n",
            "OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "\n",
            "‚úÖ API key configured!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure training parameters for T4 GPU\n",
        "from raft_config import RAFTConfig, ModelConfig, TrainingConfig, RAFTDataConfig\n",
        "\n",
        "# Create custom config optimized for T4\n",
        "config = RAFTConfig()\n",
        "\n",
        "# Model settings (optimized for T4 15GB)\n",
        "config.model.max_seq_length = 2048  # Reduced for T4\n",
        "config.model.lora_r = 16  # Smaller LoRA rank\n",
        "config.model.lora_alpha = 32\n",
        "config.model.load_in_4bit = True\n",
        "\n",
        "# Training settings (optimized for T4)\n",
        "config.training.num_train_epochs = 2  # Fewer epochs for demo\n",
        "config.training.per_device_train_batch_size = 1  # Small batch for T4\n",
        "config.training.gradient_accumulation_steps = 8  # Effective batch size = 8\n",
        "config.training.learning_rate = 2e-4\n",
        "config.training.max_new_tokens = 512  # Reduced for T4\n",
        "config.training.logging_steps = 10\n",
        "config.training.eval_steps = 50\n",
        "config.training.save_steps = 100\n",
        "\n",
        "# RAFT settings\n",
        "config.raft_data.oracle_percentage = 0.8\n",
        "config.raft_data.num_distractors = 3  # Fewer distractors\n",
        "config.raft_data.chunk_size = 1000  # Smaller chunks\n",
        "\n",
        "# System settings\n",
        "config.system.project_name = \"raft-colab\"\n",
        "config.system.use_wandb = False  # Disable W&B for simplicity\n",
        "\n",
        "# Save config\n",
        "config.to_yaml(\"colab_config.yaml\")\n",
        "\n",
        "print(\"‚öôÔ∏è Configuration for T4 GPU:\")\n",
        "print(f\"  Max Sequence Length: {config.model.max_seq_length}\")\n",
        "print(f\"  LoRA Rank: {config.model.lora_r}\")\n",
        "print(f\"  Batch Size: {config.training.per_device_train_batch_size}\")\n",
        "print(f\"  Gradient Accumulation: {config.training.gradient_accumulation_steps}\")\n",
        "print(f\"  Effective Batch Size: {config.training.per_device_train_batch_size * config.training.gradient_accumulation_steps}\")\n",
        "print(f\"  Epochs: {config.training.num_train_epochs}\")\n",
        "print(f\"\\n‚úÖ Configuration saved to colab_config.yaml\")"
      ],
      "metadata": {
        "id": "configure_settings",
        "outputId": "38cfe860-0776-42f9-81ea-9945756b5cd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Configuration for T4 GPU:\n",
            "  Max Sequence Length: 2048\n",
            "  LoRA Rank: 16\n",
            "  Batch Size: 1\n",
            "  Gradient Accumulation: 8\n",
            "  Effective Batch Size: 8\n",
            "  Epochs: 2\n",
            "\n",
            "‚úÖ Configuration saved to colab_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Step 3: Load Data and Build Retrieval Index\n",
        "\n",
        "1. Load the MSRS Story-QA dataset and explore its structure.\n",
        "2. Create vector search index for document retrieval."
      ],
      "metadata": {
        "id": "data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python raft_pipeline.py --step index --config raft_config.yaml"
      ],
      "metadata": {
        "id": "4o2SZNQOubCY",
        "outputId": "5e7f2c73-69c7-448f-c90f-6d05c8cb181d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-20 04:38:50.928854: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760935130.964603    3004 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760935130.975839    3004 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760935131.008821    3004 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760935131.008867    3004 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760935131.008877    3004 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760935131.008884    3004 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-20 04:38:51.016637: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "/content/MSRS-RAFT/raft_trainer.py:14: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastLanguageModel\n",
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "2025-10-20 04:39:25 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:39:25 - RAFT - INFO - RAFT PIPELINE INITIALIZED\n",
            "INFO:RAFT: RAFT PIPELINE INITIALIZED\n",
            "2025-10-20 04:39:25 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:39:25 - RAFT - INFO - Project: MSRS-RAFT\n",
            "INFO:RAFT: Project: MSRS-RAFT\n",
            "2025-10-20 04:39:25 - RAFT - INFO - Model: Qwen/Qwen3-4B-Instruct-2507\n",
            "INFO:RAFT: Model: Qwen/Qwen3-4B-Instruct-2507\n",
            "2025-10-20 04:39:25 - RAFT - INFO - Oracle %: 0.8\n",
            "INFO:RAFT: Oracle %: 0.8\n",
            "2025-10-20 04:39:25 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:39:25 - RAFT.Pipeline - INFO - Data not loaded, loading first...\n",
            "INFO:RAFT.Pipeline: Data not loaded, loading first...\n",
            "2025-10-20 04:39:25 - RAFT - INFO - \n",
            "============================================================\n",
            "INFO:RAFT: \n",
            "============================================================\n",
            "2025-10-20 04:39:25 - RAFT - INFO - STEP 1: LOADING DATA\n",
            "INFO:RAFT: STEP 1: LOADING DATA\n",
            "2025-10-20 04:39:25 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:39:25 - RAFT.DataLoader - INFO - Initialized MSRS loader for yale-nlp/MSRS/story-qa\n",
            "INFO:RAFT.DataLoader: Initialized MSRS loader for yale-nlp/MSRS/story-qa\n",
            "2025-10-20 04:39:25 - RAFT - INFO - Loading dataset splits...\n",
            "INFO:RAFT: Loading dataset splits...\n",
            "2025-10-20 04:39:25 - RAFT.DataLoader - INFO - Loading dataset: yale-nlp/MSRS/story-qa\n",
            "INFO:RAFT.DataLoader: Loading dataset: yale-nlp/MSRS/story-qa\n",
            "README.md: 1.96kB [00:00, 3.91MB/s]\n",
            "train.jsonl: 1.39MB [00:00, 43.4MB/s]\n",
            "dev.jsonl: 701kB [00:00, 52.0MB/s]\n",
            "test.jsonl: 1.46MB [00:00, 35.9MB/s]\n",
            "Generating train split: 100% 250/250 [00:00<00:00, 3831.02 examples/s]\n",
            "Generating validation split: 100% 125/125 [00:00<00:00, 6676.02 examples/s]\n",
            "Generating test split: 100% 260/260 [00:00<00:00, 8298.98 examples/s]\n",
            "2025-10-20 04:39:28 - RAFT.DataLoader - INFO - Loaded all splits: train=250, validation=125, test=260\n",
            "INFO:RAFT.DataLoader: Loaded all splits: train=250, validation=125, test=260\n",
            "2025-10-20 04:39:28 - RAFT - INFO - Loading story corpus...\n",
            "INFO:RAFT: Loading story corpus...\n",
            "2025-10-20 04:39:28 - RAFT.DataLoader - INFO - Loading corpus from HuggingFace dataset\n",
            "INFO:RAFT.DataLoader: Loading corpus from HuggingFace dataset\n",
            "2025-10-20 04:39:28 - RAFT.DataLoader - INFO - Attempting to load story-corpus from HuggingFace...\n",
            "INFO:RAFT.DataLoader: Attempting to load story-corpus from HuggingFace...\n",
            "corpus.jsonl: 3.99MB [00:00, 39.8MB/s]\n",
            "Generating corpus split: 100% 1138/1138 [00:00<00:00, 11565.64 examples/s]\n",
            "2025-10-20 04:39:29 - RAFT.DataLoader - INFO - Loaded corpus dataset with 1138 items\n",
            "INFO:RAFT.DataLoader: Loaded corpus dataset with 1138 items\n",
            "Loading corpus: 100% 1138/1138 [00:00<00:00, 4721.12it/s]\n",
            "2025-10-20 04:39:29 - RAFT.DataLoader - INFO - Successfully loaded 1138 chapters from HuggingFace\n",
            "INFO:RAFT.DataLoader: Successfully loaded 1138 chapters from HuggingFace\n",
            "2025-10-20 04:39:29 - RAFT.DataLoader - INFO - Loaded corpus: 1138 chapters across 1138 stories\n",
            "INFO:RAFT.DataLoader: Loaded corpus: 1138 chapters across 1138 stories\n",
            "2025-10-20 04:39:29 - RAFT - INFO - \n",
            "Dataset Statistics:\n",
            "INFO:RAFT: \n",
            "Dataset Statistics:\n",
            "2025-10-20 04:39:29 - RAFT - INFO - {\n",
            "  \"dataset_name\": \"yale-nlp/MSRS\",\n",
            "  \"dataset_config\": \"story-qa\",\n",
            "  \"splits\": {\n",
            "    \"train\": 250,\n",
            "    \"validation\": 125,\n",
            "    \"test\": 260\n",
            "  },\n",
            "  \"corpus\": {\n",
            "    \"total_chapters\": 1138,\n",
            "    \"total_stories\": 1138,\n",
            "    \"avg_chapters_per_story\": 1.0,\n",
            "    \"avg_tokens_per_chapter\": 556.9323374340948,\n",
            "    \"total_tokens\": 633789\n",
            "  }\n",
            "}\n",
            "INFO:RAFT: {\n",
            "  \"dataset_name\": \"yale-nlp/MSRS\",\n",
            "  \"dataset_config\": \"story-qa\",\n",
            "  \"splits\": {\n",
            "    \"train\": 250,\n",
            "    \"validation\": 125,\n",
            "    \"test\": 260\n",
            "  },\n",
            "  \"corpus\": {\n",
            "    \"total_chapters\": 1138,\n",
            "    \"total_stories\": 1138,\n",
            "    \"avg_chapters_per_story\": 1.0,\n",
            "    \"avg_tokens_per_chapter\": 556.9323374340948,\n",
            "    \"total_tokens\": 633789\n",
            "  }\n",
            "}\n",
            "2025-10-20 04:39:29 - RAFT - INFO - ‚úì Data loading complete\n",
            "INFO:RAFT: ‚úì Data loading complete\n",
            "2025-10-20 04:39:29 - RAFT - INFO - \n",
            "============================================================\n",
            "INFO:RAFT: \n",
            "============================================================\n",
            "2025-10-20 04:39:29 - RAFT - INFO - STEP 2: BUILDING RETRIEVAL INDEX\n",
            "INFO:RAFT: STEP 2: BUILDING RETRIEVAL INDEX\n",
            "2025-10-20 04:39:29 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:39:29 - RAFT.Retrieval - INFO - Initialized chunker: size=1500, overlap=200\n",
            "INFO:RAFT.Retrieval: Initialized chunker: size=1500, overlap=200\n",
            "INFO:sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: BAAI/bge-m3\n",
            "modules.json: 100% 349/349 [00:00<00:00, 1.61MB/s]\n",
            "config_sentence_transformers.json: 100% 123/123 [00:00<00:00, 515kB/s]\n",
            "README.md: 15.8kB [00:00, 39.3MB/s]\n",
            "sentence_bert_config.json: 100% 54.0/54.0 [00:00<00:00, 360kB/s]\n",
            "config.json: 100% 687/687 [00:00<00:00, 4.24MB/s]\n",
            "pytorch_model.bin: 100% 2.27G/2.27G [00:23<00:00, 98.5MB/s]\n",
            "model.safetensors:   3% 67.0M/2.27G [00:01<00:44, 49.3MB/s]\n",
            "tokenizer_config.json: 100% 444/444 [00:00<00:00, 3.12MB/s]\n",
            "\n",
            "model.safetensors:   8% 192M/2.27G [00:09<01:34, 22.0MB/s]\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:01<00:00, 3.67MB/s]\n",
            "\n",
            "model.safetensors:  97% 2.20G/2.27G [00:49<00:00, 79.0MB/s]\n",
            "tokenizer.json: 100% 17.1M/17.1M [00:39<00:00, 431kB/s]\n",
            "model.safetensors: 100% 2.27G/2.27G [00:49<00:00, 46.0MB/s]\n",
            "special_tokens_map.json: 100% 964/964 [00:00<00:00, 7.45MB/s]\n",
            "config.json: 100% 191/191 [00:00<00:00, 1.90MB/s]\n",
            "2025-10-20 04:40:52 - RAFT.Retrieval - INFO - Loaded embedding model: BAAI/bge-m3 on cuda\n",
            "INFO:RAFT.Retrieval: Loaded embedding model: BAAI/bge-m3 on cuda\n",
            "config.json: 100% 795/795 [00:00<00:00, 7.60MB/s]\n",
            "model.safetensors: 100% 2.27G/2.27G [01:19<00:00, 28.7MB/s]\n",
            "tokenizer_config.json: 1.17kB [00:00, 5.78MB/s]\n",
            "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 7.37MB/s]\n",
            "tokenizer.json: 100% 17.1M/17.1M [00:00<00:00, 70.0MB/s]\n",
            "special_tokens_map.json: 100% 964/964 [00:00<00:00, 9.13MB/s]\n",
            "README.md: 17.2kB [00:00, 63.4MB/s]\n",
            "2025-10-20 04:42:21 - RAFT.Retrieval - INFO - Loaded reranker: BAAI/bge-reranker-v2-m3 on cuda\n",
            "INFO:RAFT.Retrieval: Loaded reranker: BAAI/bge-reranker-v2-m3 on cuda\n",
            "2025-10-20 04:42:21 - RAFT.Retrieval - INFO - Initialized retrieval system\n",
            "INFO:RAFT.Retrieval: Initialized retrieval system\n",
            "2025-10-20 04:42:21 - RAFT - INFO - Building index for 1138 documents...\n",
            "INFO:RAFT: Building index for 1138 documents...\n",
            "2025-10-20 04:42:21 - RAFT.Retrieval - INFO - Building index from 1138 documents\n",
            "INFO:RAFT.Retrieval: Building index from 1138 documents\n",
            "Chunking documents: 100% 12/12 [00:00<00:00, 270.54it/s]\n",
            "2025-10-20 04:42:21 - RAFT.Retrieval - INFO - Created 1167 chunks from 1138 documents\n",
            "INFO:RAFT.Retrieval: Created 1167 chunks from 1138 documents\n",
            "2025-10-20 04:42:21 - RAFT.Retrieval - INFO - Encoding chunks...\n",
            "INFO:RAFT.Retrieval: Encoding chunks...\n",
            "Batches: 100% 37/37 [03:43<00:00,  6.03s/it]\n",
            "2025-10-20 04:46:04 - RAFT.Retrieval - INFO - Initialized FAISS index: type=flat, metric=cosine\n",
            "INFO:RAFT.Retrieval: Initialized FAISS index: type=flat, metric=cosine\n",
            "2025-10-20 04:46:04 - RAFT.Retrieval - INFO - Added 1167 embeddings to index\n",
            "INFO:RAFT.Retrieval: Added 1167 embeddings to index\n",
            "2025-10-20 04:46:04 - RAFT.Retrieval - INFO - Total index size: 1167\n",
            "INFO:RAFT.Retrieval: Total index size: 1167\n",
            "2025-10-20 04:46:04 - RAFT.Retrieval - INFO - Saved index to indices/raft_index\n",
            "INFO:RAFT.Retrieval: Saved index to indices/raft_index\n",
            "2025-10-20 04:46:04 - RAFT.Retrieval - INFO - Saved retrieval system to indices/raft_index\n",
            "INFO:RAFT.Retrieval: Saved retrieval system to indices/raft_index\n",
            "2025-10-20 04:46:04 - RAFT.Retrieval - INFO - Index building complete\n",
            "INFO:RAFT.Retrieval: Index building complete\n",
            "2025-10-20 04:46:04 - RAFT - INFO - ‚úì Index built and saved to indices/raft_index\n",
            "INFO:RAFT: ‚úì Index built and saved to indices/raft_index\n",
            "2025-10-20 04:46:04 - RAFT - INFO - \n",
            "‚úì All requested steps completed successfully!\n",
            "INFO:RAFT: \n",
            "‚úì All requested steps completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèóÔ∏è Step 4: Generate RAFT Training Dataset\n",
        "\n",
        "Create RAFT training examples with Chain-of-Thought reasoning and citations.\n",
        "\n",
        "**Note**: This step uses OpenAI API and will incur costs (~$0.01-0.03 per example)."
      ],
      "metadata": {
        "id": "raft_data_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python raft_pipeline.py \\\n",
        "  --step dataset \\\n",
        "  --config raft_config.yaml \\\n",
        "  --train-max-examples 100"
      ],
      "metadata": {
        "id": "generate_raft_data",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a8aaf0-4ebb-4fb4-82a1-012c95f4bd4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-17 08:40:11.823310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760690411.845029    5569 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760690411.852368    5569 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760690411.870956    5569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760690411.870982    5569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760690411.870986    5569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760690411.870991    5569 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-17 08:40:11.875761: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.0         Please see GitHub issue #2919 for more info\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "2025-10-17 08:40:25 - RAFT - INFO - ============================================================\n",
            "2025-10-17 08:40:25 - RAFT - INFO - RAFT PIPELINE INITIALIZED\n",
            "2025-10-17 08:40:25 - RAFT - INFO - ============================================================\n",
            "2025-10-17 08:40:25 - RAFT - INFO - Project: MSRS-RAFT\n",
            "2025-10-17 08:40:25 - RAFT - INFO - Model: Qwen/Qwen3-4B-Instruct-2507\n",
            "2025-10-17 08:40:25 - RAFT - INFO - Oracle %: 0.8\n",
            "2025-10-17 08:40:25 - RAFT - INFO - ============================================================\n",
            "2025-10-17 08:40:25 - RAFT.Pipeline - INFO - Data not loaded, loading first...\n",
            "2025-10-17 08:40:25 - RAFT - INFO - \n",
            "============================================================\n",
            "2025-10-17 08:40:25 - RAFT - INFO - STEP 1: LOADING DATA\n",
            "2025-10-17 08:40:25 - RAFT - INFO - ============================================================\n",
            "2025-10-17 08:40:25 - RAFT.DataLoader - INFO - Initialized MSRS loader for yale-nlp/MSRS/story-qa\n",
            "2025-10-17 08:40:25 - RAFT - INFO - Loading dataset splits...\n",
            "2025-10-17 08:40:25 - RAFT.DataLoader - INFO - Loading dataset: yale-nlp/MSRS/story-qa\n",
            "2025-10-17 08:40:26 - RAFT.DataLoader - INFO - Loaded all splits: train=250, validation=125, test=260\n",
            "2025-10-17 08:40:26 - RAFT - INFO - Loading story corpus...\n",
            "2025-10-17 08:40:26 - RAFT.DataLoader - INFO - Loading corpus from HuggingFace dataset\n",
            "2025-10-17 08:40:26 - RAFT.DataLoader - INFO - Attempting to load story-corpus from HuggingFace...\n",
            "2025-10-17 08:40:27 - RAFT.DataLoader - INFO - Loaded corpus dataset with 1138 items\n",
            "Loading corpus: 100% 1138/1138 [00:00<00:00, 13873.93it/s]\n",
            "2025-10-17 08:40:27 - RAFT.DataLoader - INFO - Successfully loaded 1138 chapters from HuggingFace\n",
            "2025-10-17 08:40:27 - RAFT.DataLoader - INFO - Loaded corpus: 1138 chapters across 1138 stories\n",
            "2025-10-17 08:40:27 - RAFT - INFO - \n",
            "Dataset Statistics:\n",
            "2025-10-17 08:40:27 - RAFT - INFO - {\n",
            "  \"dataset_name\": \"yale-nlp/MSRS\",\n",
            "  \"dataset_config\": \"story-qa\",\n",
            "  \"splits\": {\n",
            "    \"train\": 250,\n",
            "    \"validation\": 125,\n",
            "    \"test\": 260\n",
            "  },\n",
            "  \"corpus\": {\n",
            "    \"total_chapters\": 1138,\n",
            "    \"total_stories\": 1138,\n",
            "    \"avg_chapters_per_story\": 1.0,\n",
            "    \"avg_tokens_per_chapter\": 556.9323374340948,\n",
            "    \"total_tokens\": 633789\n",
            "  }\n",
            "}\n",
            "2025-10-17 08:40:27 - RAFT - INFO - ‚úì Data loading complete\n",
            "2025-10-17 08:40:27 - RAFT.Pipeline - INFO - Index not built, building first...\n",
            "2025-10-17 08:40:27 - RAFT - INFO - \n",
            "============================================================\n",
            "2025-10-17 08:40:27 - RAFT - INFO - STEP 2: BUILDING RETRIEVAL INDEX\n",
            "2025-10-17 08:40:27 - RAFT - INFO - ============================================================\n",
            "2025-10-17 08:40:27 - RAFT - INFO - Existing index found at indices/raft_index, loading instead of rebuilding...\n",
            "2025-10-17 08:40:27 - RAFT.Retrieval - INFO - Initialized chunker: size=1500, overlap=200\n",
            "2025-10-17 08:40:37 - RAFT.Retrieval - INFO - Loaded embedding model: BAAI/bge-m3 on cuda\n",
            "2025-10-17 08:40:47 - RAFT.Retrieval - INFO - Loaded reranker: BAAI/bge-reranker-v2-m3 on cuda\n",
            "2025-10-17 08:40:47 - RAFT.Retrieval - INFO - Initialized FAISS index: type=flat, metric=cosine\n",
            "2025-10-17 08:40:47 - RAFT.Retrieval - INFO - Loaded index from indices/raft_index: 1167 vectors\n",
            "2025-10-17 08:40:47 - RAFT.Retrieval - INFO - Loaded retrieval system from indices/raft_index\n",
            "2025-10-17 08:40:47 - RAFT.Retrieval - INFO - Initialized retrieval system\n",
            "2025-10-17 08:40:47 - RAFT - INFO - ‚úì Loaded existing retrieval index\n",
            "2025-10-17 08:40:47 - RAFT - INFO - \n",
            "============================================================\n",
            "2025-10-17 08:40:47 - RAFT - INFO - STEP 3: BUILDING RAFT DATASET (train split)\n",
            "2025-10-17 08:40:47 - RAFT - INFO - ============================================================\n",
            "2025-10-17 08:40:47 - RAFT.DatasetBuilder - INFO - Initialized CoT generator with model: gpt-4.1\n",
            "2025-10-17 08:40:47 - RAFT.DatasetBuilder - INFO - Initialized RAFT builder: P=0.8, distractors=4\n",
            "2025-10-17 08:40:47 - RAFT - INFO - Preparing examples from data loader...\n",
            "2025-10-17 08:40:47 - RAFT.DataLoader - INFO - Parsing 250 examples from train split\n",
            "Parsing train: 100% 250/250 [00:00<00:00, 6254.89it/s]\n",
            "2025-10-17 08:40:47 - RAFT.DataLoader - INFO - Parsed 250 examples, avg 9.18 gold docs per example\n",
            "2025-10-17 08:40:47 - RAFT - INFO - Limited to 100 examples\n",
            "2025-10-17 08:40:47 - RAFT - INFO - Building RAFT dataset with 100 examples...\n",
            "2025-10-17 08:40:47 - RAFT - INFO - Oracle percentage: 0.8\n",
            "2025-10-17 08:40:47 - RAFT - INFO - Distractors per example: 4\n",
            "2025-10-17 08:40:47 - RAFT.DatasetBuilder - INFO - Building RAFT dataset from 100 examples\n",
            "Building RAFT dataset:   0% 0/100 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python raft_pipeline.py \\\n",
        "  --step dataset \\\n",
        "  --split dev \\\n",
        "  --eval-max-examples 20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06uySPMFndcC",
        "outputId": "b10898d1-a315-4417-a79c-9c48f3d3c636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-20 04:46:36.063266: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760935596.124929    4989 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760935596.159974    4989 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760935596.309843    4989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760935596.309886    4989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760935596.309893    4989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760935596.309900    4989 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-20 04:46:36.343925: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "/content/MSRS-RAFT/raft_trainer.py:14: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastLanguageModel\n",
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "2025-10-20 04:47:15 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:47:15 - RAFT - INFO - RAFT PIPELINE INITIALIZED\n",
            "INFO:RAFT: RAFT PIPELINE INITIALIZED\n",
            "2025-10-20 04:47:15 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:47:15 - RAFT - INFO - Project: MSRS-RAFT\n",
            "INFO:RAFT: Project: MSRS-RAFT\n",
            "2025-10-20 04:47:15 - RAFT - INFO - Model: Qwen/Qwen3-4B-Instruct-2507\n",
            "INFO:RAFT: Model: Qwen/Qwen3-4B-Instruct-2507\n",
            "2025-10-20 04:47:15 - RAFT - INFO - Oracle %: 0.8\n",
            "INFO:RAFT: Oracle %: 0.8\n",
            "2025-10-20 04:47:15 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:47:15 - RAFT.Pipeline - INFO - Data not loaded, loading first...\n",
            "INFO:RAFT.Pipeline: Data not loaded, loading first...\n",
            "2025-10-20 04:47:15 - RAFT - INFO - \n",
            "============================================================\n",
            "INFO:RAFT: \n",
            "============================================================\n",
            "2025-10-20 04:47:15 - RAFT - INFO - STEP 1: LOADING DATA\n",
            "INFO:RAFT: STEP 1: LOADING DATA\n",
            "2025-10-20 04:47:15 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:47:15 - RAFT.DataLoader - INFO - Initialized MSRS loader for yale-nlp/MSRS/story-qa\n",
            "INFO:RAFT.DataLoader: Initialized MSRS loader for yale-nlp/MSRS/story-qa\n",
            "2025-10-20 04:47:15 - RAFT - INFO - Loading dataset splits...\n",
            "INFO:RAFT: Loading dataset splits...\n",
            "2025-10-20 04:47:15 - RAFT.DataLoader - INFO - Loading dataset: yale-nlp/MSRS/story-qa\n",
            "INFO:RAFT.DataLoader: Loading dataset: yale-nlp/MSRS/story-qa\n",
            "2025-10-20 04:47:17 - RAFT.DataLoader - INFO - Loaded all splits: train=250, validation=125, test=260\n",
            "INFO:RAFT.DataLoader: Loaded all splits: train=250, validation=125, test=260\n",
            "2025-10-20 04:47:17 - RAFT - INFO - Loading story corpus...\n",
            "INFO:RAFT: Loading story corpus...\n",
            "2025-10-20 04:47:17 - RAFT.DataLoader - INFO - Loading corpus from HuggingFace dataset\n",
            "INFO:RAFT.DataLoader: Loading corpus from HuggingFace dataset\n",
            "2025-10-20 04:47:17 - RAFT.DataLoader - INFO - Attempting to load story-corpus from HuggingFace...\n",
            "INFO:RAFT.DataLoader: Attempting to load story-corpus from HuggingFace...\n",
            "2025-10-20 04:47:17 - RAFT.DataLoader - INFO - Loaded corpus dataset with 1138 items\n",
            "INFO:RAFT.DataLoader: Loaded corpus dataset with 1138 items\n",
            "Loading corpus: 100% 1138/1138 [00:00<00:00, 12749.90it/s]\n",
            "2025-10-20 04:47:17 - RAFT.DataLoader - INFO - Successfully loaded 1138 chapters from HuggingFace\n",
            "INFO:RAFT.DataLoader: Successfully loaded 1138 chapters from HuggingFace\n",
            "2025-10-20 04:47:17 - RAFT.DataLoader - INFO - Loaded corpus: 1138 chapters across 1138 stories\n",
            "INFO:RAFT.DataLoader: Loaded corpus: 1138 chapters across 1138 stories\n",
            "2025-10-20 04:47:17 - RAFT - INFO - \n",
            "Dataset Statistics:\n",
            "INFO:RAFT: \n",
            "Dataset Statistics:\n",
            "2025-10-20 04:47:17 - RAFT - INFO - {\n",
            "  \"dataset_name\": \"yale-nlp/MSRS\",\n",
            "  \"dataset_config\": \"story-qa\",\n",
            "  \"splits\": {\n",
            "    \"train\": 250,\n",
            "    \"validation\": 125,\n",
            "    \"test\": 260\n",
            "  },\n",
            "  \"corpus\": {\n",
            "    \"total_chapters\": 1138,\n",
            "    \"total_stories\": 1138,\n",
            "    \"avg_chapters_per_story\": 1.0,\n",
            "    \"avg_tokens_per_chapter\": 556.9323374340948,\n",
            "    \"total_tokens\": 633789\n",
            "  }\n",
            "}\n",
            "INFO:RAFT: {\n",
            "  \"dataset_name\": \"yale-nlp/MSRS\",\n",
            "  \"dataset_config\": \"story-qa\",\n",
            "  \"splits\": {\n",
            "    \"train\": 250,\n",
            "    \"validation\": 125,\n",
            "    \"test\": 260\n",
            "  },\n",
            "  \"corpus\": {\n",
            "    \"total_chapters\": 1138,\n",
            "    \"total_stories\": 1138,\n",
            "    \"avg_chapters_per_story\": 1.0,\n",
            "    \"avg_tokens_per_chapter\": 556.9323374340948,\n",
            "    \"total_tokens\": 633789\n",
            "  }\n",
            "}\n",
            "2025-10-20 04:47:17 - RAFT - INFO - ‚úì Data loading complete\n",
            "INFO:RAFT: ‚úì Data loading complete\n",
            "2025-10-20 04:47:17 - RAFT.Pipeline - INFO - Index not built, building first...\n",
            "INFO:RAFT.Pipeline: Index not built, building first...\n",
            "2025-10-20 04:47:17 - RAFT - INFO - \n",
            "============================================================\n",
            "INFO:RAFT: \n",
            "============================================================\n",
            "2025-10-20 04:47:17 - RAFT - INFO - STEP 2: BUILDING RETRIEVAL INDEX\n",
            "INFO:RAFT: STEP 2: BUILDING RETRIEVAL INDEX\n",
            "2025-10-20 04:47:17 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:47:17 - RAFT - INFO - Existing index found at indices/raft_index, loading instead of rebuilding...\n",
            "INFO:RAFT: Existing index found at indices/raft_index, loading instead of rebuilding...\n",
            "2025-10-20 04:47:17 - RAFT.Retrieval - INFO - Initialized chunker: size=1500, overlap=200\n",
            "INFO:RAFT.Retrieval: Initialized chunker: size=1500, overlap=200\n",
            "INFO:sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: BAAI/bge-m3\n",
            "2025-10-20 04:47:32 - RAFT.Retrieval - INFO - Loaded embedding model: BAAI/bge-m3 on cuda\n",
            "INFO:RAFT.Retrieval: Loaded embedding model: BAAI/bge-m3 on cuda\n",
            "2025-10-20 04:47:44 - RAFT.Retrieval - INFO - Loaded reranker: BAAI/bge-reranker-v2-m3 on cuda\n",
            "INFO:RAFT.Retrieval: Loaded reranker: BAAI/bge-reranker-v2-m3 on cuda\n",
            "2025-10-20 04:47:44 - RAFT.Retrieval - INFO - Initialized FAISS index: type=flat, metric=cosine\n",
            "INFO:RAFT.Retrieval: Initialized FAISS index: type=flat, metric=cosine\n",
            "2025-10-20 04:47:44 - RAFT.Retrieval - INFO - Loaded index from indices/raft_index: 1167 vectors\n",
            "INFO:RAFT.Retrieval: Loaded index from indices/raft_index: 1167 vectors\n",
            "2025-10-20 04:47:44 - RAFT.Retrieval - INFO - Loaded retrieval system from indices/raft_index\n",
            "INFO:RAFT.Retrieval: Loaded retrieval system from indices/raft_index\n",
            "2025-10-20 04:47:44 - RAFT.Retrieval - INFO - Initialized retrieval system\n",
            "INFO:RAFT.Retrieval: Initialized retrieval system\n",
            "2025-10-20 04:47:44 - RAFT - INFO - ‚úì Loaded existing retrieval index\n",
            "INFO:RAFT: ‚úì Loaded existing retrieval index\n",
            "2025-10-20 04:47:44 - RAFT - INFO - \n",
            "============================================================\n",
            "INFO:RAFT: \n",
            "============================================================\n",
            "2025-10-20 04:47:44 - RAFT - INFO - STEP 3: BUILDING RAFT DATASET (dev split)\n",
            "INFO:RAFT: STEP 3: BUILDING RAFT DATASET (dev split)\n",
            "2025-10-20 04:47:44 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:47:44 - RAFT.DatasetBuilder - INFO - Initialized CoT generator with model: gpt-4-turbo-preview\n",
            "INFO:RAFT.DatasetBuilder: Initialized CoT generator with model: gpt-4-turbo-preview\n",
            "2025-10-20 04:47:44 - RAFT.DatasetBuilder - INFO - Initialized RAFT builder: P=0.8, distractors=4\n",
            "INFO:RAFT.DatasetBuilder: Initialized RAFT builder: P=0.8, distractors=4\n",
            "2025-10-20 04:47:44 - RAFT - INFO - Preparing examples from data loader...\n",
            "INFO:RAFT: Preparing examples from data loader...\n",
            "2025-10-20 04:47:44 - RAFT.DataLoader - INFO - Parsing 125 examples from validation split\n",
            "INFO:RAFT.DataLoader: Parsing 125 examples from validation split\n",
            "Parsing validation: 100% 125/125 [00:00<00:00, 5790.87it/s]\n",
            "2025-10-20 04:47:44 - RAFT.DataLoader - INFO - Parsed 125 examples, avg 8.88 gold docs per example\n",
            "INFO:RAFT.DataLoader: Parsed 125 examples, avg 8.88 gold docs per example\n",
            "2025-10-20 04:47:44 - RAFT - INFO - Limited to 20 examples\n",
            "INFO:RAFT: Limited to 20 examples\n",
            "2025-10-20 04:47:44 - RAFT - INFO - Building RAFT dataset with 20 examples...\n",
            "INFO:RAFT: Building RAFT dataset with 20 examples...\n",
            "2025-10-20 04:47:44 - RAFT - INFO - Oracle percentage: 0.8\n",
            "INFO:RAFT: Oracle percentage: 0.8\n",
            "2025-10-20 04:47:44 - RAFT - INFO - Distractors per example: 4\n",
            "INFO:RAFT: Distractors per example: 4\n",
            "2025-10-20 04:47:44 - RAFT.DatasetBuilder - INFO - Building RAFT dataset from 20 examples\n",
            "INFO:RAFT.DatasetBuilder: Building RAFT dataset from 20 examples\n",
            "Building RAFT dataset:   0% 0/20 [00:00<?, ?it/s]\n",
            "Batches:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Batches: 100% 1/1 [00:12<00:00, 12.06s/it]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.400828 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.820584 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:48:01 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:48:01 - RAFT.DatasetBuilder - ERROR - Failed to build example 510: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 510: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:   5% 1/20 [00:16<05:21, 16.93s/it]\n",
            "Batches:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Batches: 100% 1/1 [00:00<00:00,  9.71it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.420123 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.997788 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:48:16 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:48:16 - RAFT.DatasetBuilder - ERROR - Failed to build example 511: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 511: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  10% 2/20 [00:31<04:42, 15.72s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 11.17it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.421481 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.969333 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:48:31 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:48:31 - RAFT.DatasetBuilder - ERROR - Failed to build example 512: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 512: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  15% 3/20 [00:46<04:20, 15.34s/it]\n",
            "Batches:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Batches: 100% 1/1 [00:00<00:00,  3.33it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.428243 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.850089 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:48:41 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:48:41 - RAFT.DatasetBuilder - ERROR - Failed to build example 513: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 513: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  20% 4/20 [00:56<03:32, 13.29s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 11.64it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.493523 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.900070 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:48:55 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:48:55 - RAFT.DatasetBuilder - ERROR - Failed to build example 514: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 514: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  25% 5/20 [01:11<03:25, 13.69s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 10.40it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.443011 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.950623 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:49:05 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:49:05 - RAFT.DatasetBuilder - ERROR - Failed to build example 515: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 515: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  30% 6/20 [01:21<02:53, 12.40s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 12.55it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.425580 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.824534 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:49:15 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:49:15 - RAFT.DatasetBuilder - ERROR - Failed to build example 516: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 516: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  35% 7/20 [01:30<02:29, 11.54s/it]\n",
            "Batches:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Batches: 100% 1/1 [00:00<00:00,  9.78it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.417786 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.824754 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:49:27 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:49:27 - RAFT.DatasetBuilder - ERROR - Failed to build example 517: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 517: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  40% 8/20 [01:43<02:20, 11.74s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 13.15it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.394852 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.782824 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:49:37 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:49:37 - RAFT.DatasetBuilder - ERROR - Failed to build example 518: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 518: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  45% 9/20 [01:53<02:03, 11.21s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 13.40it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.495702 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.921787 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:49:47 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:49:47 - RAFT.DatasetBuilder - ERROR - Failed to build example 519: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 519: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  50% 10/20 [02:03<01:48, 10.86s/it]\n",
            "Batches:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Batches: 100% 1/1 [00:00<00:00,  8.95it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.445508 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.829265 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:50:02 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:50:02 - RAFT.DatasetBuilder - ERROR - Failed to build example 520: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 520: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  55% 11/20 [02:17<01:47, 11.98s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 12.10it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.485649 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.804606 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:50:16 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:50:16 - RAFT.DatasetBuilder - ERROR - Failed to build example 521: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 521: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  60% 12/20 [02:31<01:40, 12.58s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 11.47it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.466906 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.909837 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:50:30 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:50:30 - RAFT.DatasetBuilder - ERROR - Failed to build example 522: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 522: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  65% 13/20 [02:45<01:30, 12.98s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 12.55it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.495844 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.882832 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:50:40 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:50:40 - RAFT.DatasetBuilder - ERROR - Failed to build example 523: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 523: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  70% 14/20 [02:55<01:13, 12.18s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 10.25it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.387638 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.918728 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:50:55 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:50:55 - RAFT.DatasetBuilder - ERROR - Failed to build example 524: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 524: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  75% 15/20 [03:10<01:04, 12.88s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 11.73it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.390613 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.781020 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:51:08 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:51:08 - RAFT.DatasetBuilder - ERROR - Failed to build example 525: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 525: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  80% 16/20 [03:24<00:52, 13.15s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 11.72it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.417901 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.866659 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:51:19 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:51:19 - RAFT.DatasetBuilder - ERROR - Failed to build example 526: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 526: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  85% 17/20 [03:34<00:36, 12.29s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 11.14it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.413913 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.899199 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:51:33 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:51:33 - RAFT.DatasetBuilder - ERROR - Failed to build example 527: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 527: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  90% 18/20 [03:48<00:25, 12.82s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 11.87it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.454985 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.952878 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:51:43 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:51:43 - RAFT.DatasetBuilder - ERROR - Failed to build example 528: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 528: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset:  95% 19/20 [03:58<00:12, 12.05s/it]\n",
            "Batches: 100% 1/1 [00:00<00:00, 10.68it/s]\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.413745 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "INFO:openai._base_client: Retrying request to /chat/completions in 0.836073 seconds\n",
            "INFO:httpx: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 429 Too Many Requests\"\n",
            "2025-10-20 04:51:58 - RAFT.DatasetBuilder - ERROR - Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to generate CoT with OpenAI client: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "2025-10-20 04:51:58 - RAFT.DatasetBuilder - ERROR - Failed to build example 529: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "ERROR:RAFT.DatasetBuilder: Failed to build example 529: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Building RAFT dataset: 100% 20/20 [04:13<00:00, 12.68s/it]\n",
            "2025-10-20 04:51:58 - RAFT.DatasetBuilder - INFO - Built 0 RAFT examples (20 failed validation)\n",
            "INFO:RAFT.DatasetBuilder: Built 0 RAFT examples (20 failed validation)\n",
            "2025-10-20 04:51:58 - RAFT.DatasetBuilder - INFO - Saved 0 examples to data/raft_dev.jsonl\n",
            "INFO:RAFT.DatasetBuilder: Saved 0 examples to data/raft_dev.jsonl\n",
            "2025-10-20 04:51:58 - RAFT - INFO - \n",
            "RAFT Dataset Statistics:\n",
            "INFO:RAFT: \n",
            "RAFT Dataset Statistics:\n",
            "2025-10-20 04:51:58 - RAFT - INFO - {}\n",
            "INFO:RAFT: {}\n",
            "2025-10-20 04:51:58 - RAFT - INFO - ‚úì RAFT dataset saved to data/raft_dev.jsonl\n",
            "INFO:RAFT: ‚úì RAFT dataset saved to data/raft_dev.jsonl\n",
            "2025-10-20 04:51:58 - RAFT - INFO - \n",
            "‚úì All requested steps completed successfully!\n",
            "INFO:RAFT: \n",
            "‚úì All requested steps completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python raft_pipeline.py \\\n",
        "  --step dataset \\\n",
        "  --split test \\\n",
        "  --eval-max-examples 30"
      ],
      "metadata": {
        "id": "ApsO067TqCRk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a271026-edcf-42c4-f137-49114604f6ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-20 04:52:21.249213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1760935941.295656    6472 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1760935941.320054    6472 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1760935941.366037    6472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760935941.366076    6472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760935941.366080    6472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1760935941.366084    6472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-20 04:52:21.374025: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "/content/MSRS-RAFT/raft_trainer.py:14: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastLanguageModel\n",
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "2025-10-20 04:53:02 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:53:02 - RAFT - INFO - RAFT PIPELINE INITIALIZED\n",
            "INFO:RAFT: RAFT PIPELINE INITIALIZED\n",
            "2025-10-20 04:53:02 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:53:02 - RAFT - INFO - Project: MSRS-RAFT\n",
            "INFO:RAFT: Project: MSRS-RAFT\n",
            "2025-10-20 04:53:02 - RAFT - INFO - Model: Qwen/Qwen3-4B-Instruct-2507\n",
            "INFO:RAFT: Model: Qwen/Qwen3-4B-Instruct-2507\n",
            "2025-10-20 04:53:02 - RAFT - INFO - Oracle %: 0.8\n",
            "INFO:RAFT: Oracle %: 0.8\n",
            "2025-10-20 04:53:02 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:53:02 - RAFT.Pipeline - INFO - Data not loaded, loading first...\n",
            "INFO:RAFT.Pipeline: Data not loaded, loading first...\n",
            "2025-10-20 04:53:02 - RAFT - INFO - \n",
            "============================================================\n",
            "INFO:RAFT: \n",
            "============================================================\n",
            "2025-10-20 04:53:02 - RAFT - INFO - STEP 1: LOADING DATA\n",
            "INFO:RAFT: STEP 1: LOADING DATA\n",
            "2025-10-20 04:53:02 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:53:02 - RAFT.DataLoader - INFO - Initialized MSRS loader for yale-nlp/MSRS/story-qa\n",
            "INFO:RAFT.DataLoader: Initialized MSRS loader for yale-nlp/MSRS/story-qa\n",
            "2025-10-20 04:53:02 - RAFT - INFO - Loading dataset splits...\n",
            "INFO:RAFT: Loading dataset splits...\n",
            "2025-10-20 04:53:02 - RAFT.DataLoader - INFO - Loading dataset: yale-nlp/MSRS/story-qa\n",
            "INFO:RAFT.DataLoader: Loading dataset: yale-nlp/MSRS/story-qa\n",
            "2025-10-20 04:53:04 - RAFT.DataLoader - INFO - Loaded all splits: train=250, validation=125, test=260\n",
            "INFO:RAFT.DataLoader: Loaded all splits: train=250, validation=125, test=260\n",
            "2025-10-20 04:53:04 - RAFT - INFO - Loading story corpus...\n",
            "INFO:RAFT: Loading story corpus...\n",
            "2025-10-20 04:53:04 - RAFT.DataLoader - INFO - Loading corpus from HuggingFace dataset\n",
            "INFO:RAFT.DataLoader: Loading corpus from HuggingFace dataset\n",
            "2025-10-20 04:53:04 - RAFT.DataLoader - INFO - Attempting to load story-corpus from HuggingFace...\n",
            "INFO:RAFT.DataLoader: Attempting to load story-corpus from HuggingFace...\n",
            "2025-10-20 04:53:04 - RAFT.DataLoader - INFO - Loaded corpus dataset with 1138 items\n",
            "INFO:RAFT.DataLoader: Loaded corpus dataset with 1138 items\n",
            "Loading corpus: 100% 1138/1138 [00:00<00:00, 15048.18it/s]\n",
            "2025-10-20 04:53:04 - RAFT.DataLoader - INFO - Successfully loaded 1138 chapters from HuggingFace\n",
            "INFO:RAFT.DataLoader: Successfully loaded 1138 chapters from HuggingFace\n",
            "2025-10-20 04:53:04 - RAFT.DataLoader - INFO - Loaded corpus: 1138 chapters across 1138 stories\n",
            "INFO:RAFT.DataLoader: Loaded corpus: 1138 chapters across 1138 stories\n",
            "2025-10-20 04:53:04 - RAFT - INFO - \n",
            "Dataset Statistics:\n",
            "INFO:RAFT: \n",
            "Dataset Statistics:\n",
            "2025-10-20 04:53:04 - RAFT - INFO - {\n",
            "  \"dataset_name\": \"yale-nlp/MSRS\",\n",
            "  \"dataset_config\": \"story-qa\",\n",
            "  \"splits\": {\n",
            "    \"train\": 250,\n",
            "    \"validation\": 125,\n",
            "    \"test\": 260\n",
            "  },\n",
            "  \"corpus\": {\n",
            "    \"total_chapters\": 1138,\n",
            "    \"total_stories\": 1138,\n",
            "    \"avg_chapters_per_story\": 1.0,\n",
            "    \"avg_tokens_per_chapter\": 556.9323374340948,\n",
            "    \"total_tokens\": 633789\n",
            "  }\n",
            "}\n",
            "INFO:RAFT: {\n",
            "  \"dataset_name\": \"yale-nlp/MSRS\",\n",
            "  \"dataset_config\": \"story-qa\",\n",
            "  \"splits\": {\n",
            "    \"train\": 250,\n",
            "    \"validation\": 125,\n",
            "    \"test\": 260\n",
            "  },\n",
            "  \"corpus\": {\n",
            "    \"total_chapters\": 1138,\n",
            "    \"total_stories\": 1138,\n",
            "    \"avg_chapters_per_story\": 1.0,\n",
            "    \"avg_tokens_per_chapter\": 556.9323374340948,\n",
            "    \"total_tokens\": 633789\n",
            "  }\n",
            "}\n",
            "2025-10-20 04:53:04 - RAFT - INFO - ‚úì Data loading complete\n",
            "INFO:RAFT: ‚úì Data loading complete\n",
            "2025-10-20 04:53:04 - RAFT.Pipeline - INFO - Index not built, building first...\n",
            "INFO:RAFT.Pipeline: Index not built, building first...\n",
            "2025-10-20 04:53:04 - RAFT - INFO - \n",
            "============================================================\n",
            "INFO:RAFT: \n",
            "============================================================\n",
            "2025-10-20 04:53:04 - RAFT - INFO - STEP 2: BUILDING RETRIEVAL INDEX\n",
            "INFO:RAFT: STEP 2: BUILDING RETRIEVAL INDEX\n",
            "2025-10-20 04:53:04 - RAFT - INFO - ============================================================\n",
            "INFO:RAFT: ============================================================\n",
            "2025-10-20 04:53:04 - RAFT - INFO - Existing index found at indices/raft_index, loading instead of rebuilding...\n",
            "INFO:RAFT: Existing index found at indices/raft_index, loading instead of rebuilding...\n",
            "2025-10-20 04:53:04 - RAFT.Retrieval - INFO - Initialized chunker: size=1500, overlap=200\n",
            "INFO:RAFT.Retrieval: Initialized chunker: size=1500, overlap=200\n",
            "INFO:sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: BAAI/bge-m3\n",
            "2025-10-20 04:53:13 - RAFT.Retrieval - INFO - Loaded embedding model: BAAI/bge-m3 on cuda\n",
            "INFO:RAFT.Retrieval: Loaded embedding model: BAAI/bge-m3 on cuda\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéØ Step 5: Train Model with Unsloth\n",
        "\n",
        "Fine-tune Qwen3-4B-Instruct using QLoRA with Unsloth."
      ],
      "metadata": {
        "id": "train_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main\n",
        "!python raft_pipeline.py --step train --config raft_config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-XHz4kWoese",
        "outputId": "5ce8b977-9623-482d-c5ef-4cc4489c20b5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/limcheekin/MSRS-RAFT\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "2025-10-21 03:34:13.853864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761017653.876999   16518 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761017653.884723   16518 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761017653.904553   16518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761017653.904580   16518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761017653.904584   16518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761017653.904588   16518 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-21 03:34:13.909283: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "2025-10-21 03:34:21 - RAFT - INFO - ============================================================\n",
            "2025-10-21 03:34:21 - RAFT - INFO - RAFT PIPELINE INITIALIZED\n",
            "2025-10-21 03:34:21 - RAFT - INFO - ============================================================\n",
            "2025-10-21 03:34:21 - RAFT - INFO - Project: MSRS-RAFT\n",
            "2025-10-21 03:34:21 - RAFT - INFO - Model: Qwen/Qwen3-4B-Instruct-2507\n",
            "2025-10-21 03:34:21 - RAFT - INFO - Oracle %: 0.8\n",
            "2025-10-21 03:34:21 - RAFT - INFO - ============================================================\n",
            "2025-10-21 03:34:21 - RAFT - INFO - \n",
            "============================================================\n",
            "2025-10-21 03:34:21 - RAFT - INFO - STEP 4: TRAINING MODEL\n",
            "2025-10-21 03:34:21 - RAFT - INFO - ============================================================\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlimcheekin\u001b[0m (\u001b[33mvobject\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.22.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/MSRS-RAFT/wandb/run-20251021_033421-xa4ak9ca\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mglad-gorge-11\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vobject/MSRS-RAFT\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vobject/MSRS-RAFT/runs/xa4ak9ca\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [openai] in use.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n",
            "2025-10-21 03:34:23 - RAFT.Trainer - INFO - Initialized RAFT Trainer\n",
            "2025-10-21 03:34:23 - RAFT - INFO - Loading model and applying LoRA...\n",
            "/content/MSRS-RAFT/raft_trainer.py:533: UserWarning: WARNING: Unsloth should be imported before trl, transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  from unsloth import FastLanguageModel\n",
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "2025-10-21 03:34:38 - RAFT.Trainer - INFO - Loading model: Qwen/Qwen3-4B-Instruct-2507\n",
            "INFO:RAFT.Trainer: Loading model: Qwen/Qwen3-4B-Instruct-2507\n",
            "==((====))==  Unsloth 2025.10.7: Fast Qwen3 patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "INFO:accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "2025-10-21 03:35:03 - RAFT.Trainer - INFO - Model loaded successfully\n",
            "INFO:RAFT.Trainer: Model loaded successfully\n",
            "2025-10-21 03:35:03 - RAFT.Trainer - INFO - Applying LoRA adapters\n",
            "INFO:RAFT.Trainer: Applying LoRA adapters\n",
            "Unsloth 2025.10.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n",
            "2025-10-21 03:35:10 - RAFT.Trainer - INFO - Trainable params: 66,060,288 / 2,572,680,704 (2.57%)\n",
            "INFO:RAFT.Trainer: Trainable params: 66,060,288 / 2,572,680,704 (2.57%)\n",
            "2025-10-21 03:35:10 - RAFT - INFO - Loading training data from data/raft_train.jsonl\n",
            "INFO:RAFT: Loading training data from data/raft_train.jsonl\n",
            "2025-10-21 03:35:10 - RAFT.Trainer - INFO - Loading training dataset from data/raft_train.jsonl\n",
            "INFO:RAFT.Trainer: Loading training dataset from data/raft_train.jsonl\n",
            "2025-10-21 03:35:11 - RAFT.Trainer - INFO - Loaded 8 training examples\n",
            "INFO:RAFT.Trainer: Loaded 8 training examples\n",
            "2025-10-21 03:35:11 - RAFT.Trainer - INFO - Loading evaluation dataset from data/raft_dev.jsonl\n",
            "INFO:RAFT.Trainer: Loading evaluation dataset from data/raft_dev.jsonl\n",
            "2025-10-21 03:35:11 - RAFT.Trainer - INFO - Loaded 14 evaluation examples\n",
            "INFO:RAFT.Trainer: Loaded 14 evaluation examples\n",
            "2025-10-21 03:35:11 - RAFT - INFO - Starting training...\n",
            "INFO:RAFT: Starting training...\n",
            "2025-10-21 03:35:11 - RAFT - INFO - Epochs: 3\n",
            "INFO:RAFT: Epochs: 3\n",
            "2025-10-21 03:35:11 - RAFT - INFO - Batch size: 2\n",
            "INFO:RAFT: Batch size: 2\n",
            "2025-10-21 03:35:11 - RAFT - INFO - Learning rate: 0.0002\n",
            "INFO:RAFT: Learning rate: 0.0002\n",
            "2025-10-21 03:35:11 - RAFT.Trainer - INFO - Preparing trainer...\n",
            "INFO:RAFT.Trainer: Preparing trainer...\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Step 6: Save Trained Model\n",
        "\n",
        "Save the fine-tuned model for later use or download."
      ],
      "metadata": {
        "id": "save_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üíæ Saving trained model...\\n\")\n",
        "\n",
        "# Save model (merged 16bit for best quality)\n",
        "output_dir = \"./models/raft_qwen3_colab\"\n",
        "\n",
        "trainer.save_model(\n",
        "    output_dir=output_dir,\n",
        "    save_method=\"merged_16bit\"  # or \"lora\" for smaller size\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Model saved to {output_dir}\")\n",
        "\n",
        "# Check model size\n",
        "import os\n",
        "total_size = sum(os.path.getsize(os.path.join(dirpath, filename))\n",
        "                 for dirpath, _, filenames in os.walk(output_dir)\n",
        "                 for filename in filenames)\n",
        "print(f\"üì¶ Model size: {total_size / 1e9:.2f} GB\")\n",
        "\n",
        "# Optionally zip for download\n",
        "print(\"\\nüì¶ Creating zip file for download...\")\n",
        "!zip -r raft_model_colab.zip {output_dir}\n",
        "print(\"‚úÖ Model zipped as raft_model_colab.zip\")\n",
        "print(\"\\nYou can download this file from the Files panel on the left.\")"
      ],
      "metadata": {
        "id": "save_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Step 8: Evaluate Model\n",
        "\n",
        "Test the fine-tuned model on evaluation examples."
      ],
      "metadata": {
        "id": "eval_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python raft_pipeline.py --step eval --config raft_config.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLPP2HZLzn9c",
        "outputId": "18cac0de-ccb3-485d-c953-41eb472c57f1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-21 03:29:01.922754: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761017342.361789   15054 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761017342.478788   15054 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761017343.257357   15054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761017343.257426   15054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761017343.257435   15054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761017343.257441   15054 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-21 03:29:03.323882: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
            "  warnings.warn(\n",
            "2025-10-21 03:29:20 - RAFT - INFO - ============================================================\n",
            "2025-10-21 03:29:20 - RAFT - INFO - RAFT PIPELINE INITIALIZED\n",
            "2025-10-21 03:29:20 - RAFT - INFO - ============================================================\n",
            "2025-10-21 03:29:20 - RAFT - INFO - Project: MSRS-RAFT\n",
            "2025-10-21 03:29:20 - RAFT - INFO - Model: Qwen/Qwen3-4B-Instruct-2507\n",
            "2025-10-21 03:29:20 - RAFT - INFO - Oracle %: 0.8\n",
            "2025-10-21 03:29:20 - RAFT - INFO - ============================================================\n",
            "2025-10-21 03:29:20 - RAFT.Pipeline - INFO - Data not loaded, loading first...\n",
            "2025-10-21 03:29:20 - RAFT - INFO - \n",
            "============================================================\n",
            "2025-10-21 03:29:20 - RAFT - INFO - STEP 1: LOADING DATA\n",
            "2025-10-21 03:29:20 - RAFT - INFO - ============================================================\n",
            "2025-10-21 03:29:20 - RAFT.DataLoader - INFO - Initialized MSRS loader for yale-nlp/MSRS/story-qa\n",
            "2025-10-21 03:29:20 - RAFT - INFO - Loading dataset splits...\n",
            "2025-10-21 03:29:20 - RAFT.DataLoader - INFO - Loading dataset: yale-nlp/MSRS/story-qa\n",
            "README.md: 1.96kB [00:00, 8.30MB/s]\n",
            "train.jsonl: 1.39MB [00:00, 33.5MB/s]\n",
            "dev.jsonl: 701kB [00:00, 114MB/s]\n",
            "test.jsonl: 1.46MB [00:00, 123MB/s]\n",
            "Generating train split: 100% 250/250 [00:00<00:00, 7449.60 examples/s]\n",
            "Generating validation split: 100% 125/125 [00:00<00:00, 24841.89 examples/s]\n",
            "Generating test split: 100% 260/260 [00:00<00:00, 33184.80 examples/s]\n",
            "2025-10-21 03:29:21 - RAFT.DataLoader - INFO - Loaded all splits: train=250, validation=125, test=260\n",
            "2025-10-21 03:29:21 - RAFT - INFO - Loading story corpus...\n",
            "2025-10-21 03:29:21 - RAFT.DataLoader - INFO - Loading corpus from HuggingFace dataset\n",
            "2025-10-21 03:29:21 - RAFT.DataLoader - INFO - Attempting to load story-corpus from HuggingFace...\n",
            "corpus.jsonl: 3.99MB [00:00, 164MB/s]\n",
            "Generating corpus split: 100% 1138/1138 [00:00<00:00, 56286.77 examples/s]\n",
            "2025-10-21 03:29:22 - RAFT.DataLoader - INFO - Loaded corpus dataset with 1138 items\n",
            "Loading corpus: 100% 1138/1138 [00:00<00:00, 15907.48it/s]\n",
            "2025-10-21 03:29:22 - RAFT.DataLoader - INFO - Successfully loaded 1138 chapters from HuggingFace\n",
            "2025-10-21 03:29:22 - RAFT.DataLoader - INFO - Loaded corpus: 1138 chapters across 1138 stories\n",
            "2025-10-21 03:29:22 - RAFT - INFO - \n",
            "Dataset Statistics:\n",
            "2025-10-21 03:29:22 - RAFT - INFO - {\n",
            "  \"dataset_name\": \"yale-nlp/MSRS\",\n",
            "  \"dataset_config\": \"story-qa\",\n",
            "  \"splits\": {\n",
            "    \"train\": 250,\n",
            "    \"validation\": 125,\n",
            "    \"test\": 260\n",
            "  },\n",
            "  \"corpus\": {\n",
            "    \"total_chapters\": 1138,\n",
            "    \"total_stories\": 1138,\n",
            "    \"avg_chapters_per_story\": 1.0,\n",
            "    \"avg_tokens_per_chapter\": 556.9323374340948,\n",
            "    \"total_tokens\": 633789\n",
            "  }\n",
            "}\n",
            "2025-10-21 03:29:22 - RAFT - INFO - ‚úì Data loading complete\n",
            "2025-10-21 03:29:22 - RAFT - ERROR - No model found. Provide --model-path\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üé® Step 9: Interactive Demo\n",
        "\n",
        "Try the model with your own questions!"
      ],
      "metadata": {
        "id": "demo_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, top_k=3):\n",
        "    \"\"\"Answer a question using the trained model\"\"\"\n",
        "    print(f\"\\n‚ùì Question: {question}\")\n",
        "    print(\"\\nüîç Retrieving relevant contexts...\")\n",
        "\n",
        "    # Retrieve contexts\n",
        "    results = retrieval_system.retrieve(question, top_k=top_k)\n",
        "    contexts = [r.text for r in results]\n",
        "\n",
        "    print(f\"   Found {len(results)} relevant documents\")\n",
        "    for i, r in enumerate(results, 1):\n",
        "        print(f\"   {i}. {r.doc_id} (score: {r.score:.4f})\")\n",
        "\n",
        "    print(\"\\nü§ñ Generating answer...\\n\")\n",
        "\n",
        "    # Generate answer\n",
        "    answer = evaluator.generate_answer(question, contexts)\n",
        "\n",
        "    print(\"=\"*70)\n",
        "    print(\"ANSWER:\")\n",
        "    print(\"=\"*70)\n",
        "    print(answer)\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Try some example questions\n",
        "print(\"üé® Interactive Demo - Try the model!\\n\")\n",
        "\n",
        "# Example 1\n",
        "answer_question(\"What is the main theme of the story?\")\n",
        "\n",
        "# Example 2\n",
        "answer_question(\"Who are the main characters?\")\n",
        "\n",
        "# Try your own question\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Try your own question!\")\n",
        "print(\"=\"*70)\n",
        "custom_question = input(\"Enter your question: \")\n",
        "if custom_question.strip():\n",
        "    answer_question(custom_question)"
      ],
      "metadata": {
        "id": "interactive_demo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üì• Step 10: Download Results\n",
        "\n",
        "Package and download training artifacts."
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "print(\"üì• Preparing files for download...\\n\")\n",
        "\n",
        "# Create results package\n",
        "package_dir = \"raft_training_results\"\n",
        "!mkdir -p {package_dir}\n",
        "\n",
        "# Copy important files\n",
        "print(\"üì¶ Packaging results...\")\n",
        "\n",
        "files_to_package = [\n",
        "    (\"colab_config.yaml\", \"Configuration\"),\n",
        "    (\"./logs/training_colab.jsonl\", \"Training logs\"),\n",
        "    (\"./results/eval_colab.jsonl\", \"Evaluation results\"),\n",
        "    (\"./data/raft_train.jsonl\", \"Training data sample\"),\n",
        "]\n",
        "\n",
        "for file_path, description in files_to_package:\n",
        "    if os.path.exists(file_path):\n",
        "        shutil.copy(file_path, package_dir)\n",
        "        print(f\"  ‚úì {description}\")\n",
        "\n",
        "# Create summary report\n",
        "summary = f\"\"\"RAFT Training Summary\n",
        "=====================\n",
        "\n",
        "Training Configuration:\n",
        "- Model: Qwen3-4B-Instruct\n",
        "- LoRA Rank: {config.model.lora_r}\n",
        "- Sequence Length: {config.model.max_seq_length}\n",
        "- Batch Size: {config.training.per_device_train_batch_size}\n",
        "- Gradient Accumulation: {config.training.gradient_accumulation_steps}\n",
        "- Epochs: {config.training.num_train_epochs}\n",
        "- Learning Rate: {config.training.learning_rate}\n",
        "\n",
        "Dataset:\n",
        "- Training Examples: {len(train_dataset)}\n",
        "- Evaluation Examples: {len(eval_dataset) if eval_dataset else 0}\n",
        "- Oracle Percentage: {config.raft_data.oracle_percentage}\n",
        "- Distractors: {config.raft_data.num_distractors}\n",
        "\n",
        "Results:\n",
        "- Final Training Loss: {train_result.training_loss:.4f}\n",
        "- Evaluation Metrics: See eval_colab.jsonl\n",
        "\n",
        "Model Location: {output_dir}\n",
        "Model Size: {total_size / 1e9:.2f} GB\n",
        "\"\"\"\n",
        "\n",
        "with open(f\"{package_dir}/SUMMARY.txt\", 'w') as f:\n",
        "    f.write(summary)\n",
        "\n",
        "print(\"  ‚úì Summary report\")\n",
        "\n",
        "# Zip everything\n",
        "print(\"\\nüì¶ Creating zip file...\")\n",
        "!zip -r raft_results.zip {package_dir}\n",
        "\n",
        "print(\"\\n‚úÖ Results packaged!\")\n",
        "print(\"\\nDownload options:\")\n",
        "print(\"1. raft_results.zip - Training logs and results\")\n",
        "print(\"2. raft_model_colab.zip - Trained model (large file)\")\n",
        "print(\"\\nUse the Files panel on the left to download.\")\n",
        "\n",
        "# Optionally trigger download\n",
        "print(\"\\nüíæ Downloading results package...\")\n",
        "files.download('raft_results.zip')"
      ],
      "metadata": {
        "id": "download_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìä Step 11: Visualize Training Progress\n",
        "\n",
        "Plot training metrics."
      ],
      "metadata": {
        "id": "viz_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"üìä Visualizing training progress...\\n\")\n",
        "\n",
        "# Load training logs\n",
        "log_file = \"./logs/training_colab.jsonl\"\n",
        "if os.path.exists(log_file):\n",
        "    logs = []\n",
        "    with open(log_file, 'r') as f:\n",
        "        for line in f:\n",
        "            logs.append(json.loads(line))\n",
        "\n",
        "    # Extract metrics\n",
        "    steps = [log['step'] for log in logs if 'loss' in log]\n",
        "    losses = [log['loss'] for log in logs if 'loss' in log]\n",
        "    learning_rates = [log.get('learning_rate', 0) for log in logs if 'loss' in log]\n",
        "\n",
        "    # Create plots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Loss plot\n",
        "    ax1.plot(steps, losses, 'b-', linewidth=2)\n",
        "    ax1.set_xlabel('Training Steps', fontsize=12)\n",
        "    ax1.set_ylabel('Loss', fontsize=12)\n",
        "    ax1.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Learning rate plot\n",
        "    ax2.plot(steps, learning_rates, 'r-', linewidth=2)\n",
        "    ax2.set_xlabel('Training Steps', fontsize=12)\n",
        "    ax2.set_ylabel('Learning Rate', fontsize=12)\n",
        "    ax2.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_progress.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"‚úÖ Training visualization complete!\")\n",
        "    print(f\"   Total steps: {len(steps)}\")\n",
        "    if losses:\n",
        "        print(f\"   Initial loss: {losses[0]:.4f}\")\n",
        "        print(f\"   Final loss: {losses[-1]:.4f}\")\n",
        "        print(f\"   Improvement: {((losses[0] - losses[-1]) / losses[0] * 100):.2f}%\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Training log file not found\")"
      ],
      "metadata": {
        "id": "visualize_training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Step 12: Troubleshooting\n",
        "\n",
        "Run diagnostics if you encounter issues."
      ],
      "metadata": {
        "id": "troubleshooting_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell if you encounter issues\n",
        "\n",
        "print(\"üîç System Diagnostics\\n\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Check GPU\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
        "    print(f\"GPU Memory Cached: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")\n",
        "\n",
        "# Check disk space\n",
        "import shutil\n",
        "total, used, free = shutil.disk_usage(\"/\")\n",
        "print(f\"\\nDisk Space:\")\n",
        "print(f\"  Total: {total / 1e9:.2f} GB\")\n",
        "print(f\"  Used: {used / 1e9:.2f} GB\")\n",
        "print(f\"  Free: {free / 1e9:.2f} GB\")\n",
        "\n",
        "# Check Python packages\n",
        "print(f\"\\nKey Package Versions:\")\n",
        "import transformers\n",
        "print(f\"  transformers: {transformers.__version__}\")\n",
        "print(f\"  torch: {torch.__version__}\")\n",
        "\n",
        "try:\n",
        "    from unsloth import __version__ as unsloth_version\n",
        "    print(f\"  unsloth: {unsloth_version}\")\n",
        "except:\n",
        "    print(f\"  unsloth: installed (version unknown)\")\n",
        "\n",
        "# Check environment variables\n",
        "print(f\"\\nEnvironment:\")\n",
        "print(f\"  OPENAI_API_KEY: {'Set' if os.environ.get('OPENAI_API_KEY') else 'Not set'}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\\nCommon Solutions:\")\n",
        "print(\"  1. Out of Memory: Reduce batch_size or max_seq_length\")\n",
        "print(\"  2. API Errors: Check OpenAI API key and credits\")\n",
        "print(\"  3. Slow Training: Ensure GPU runtime is enabled\")\n",
        "print(\"  4. Import Errors: Restart runtime and reinstall packages\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "troubleshooting"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíæ Step 13: Save to Google Drive (Optional)\n",
        "\n",
        "Save your work to Google Drive to prevent data loss."
      ],
      "metadata": {
        "id": "gdrive_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create backup directory\n",
        "backup_dir = '/content/drive/MyDrive/RAFT_Backup'\n",
        "!mkdir -p {backup_dir}\n",
        "\n",
        "print(f\"üìÅ Backing up to: {backup_dir}\\n\")\n",
        "\n",
        "# Copy important files\n",
        "print(\"üíæ Copying files...\")\n",
        "!cp -r ./models/raft_qwen3_colab {backup_dir}/ 2>/dev/null || echo \"  ‚ö†Ô∏è Model not found\"\n",
        "!cp -r ./data {backup_dir}/ 2>/dev/null || echo \"  ‚ö†Ô∏è Data not found\"\n",
        "!cp -r ./results {backup_dir}/ 2>/dev/null || echo \"  ‚ö†Ô∏è Results not found\"\n",
        "!cp -r ./logs {backup_dir}/ 2>/dev/null || echo \"  ‚ö†Ô∏è Logs not found\"\n",
        "!cp colab_config.yaml {backup_dir}/ 2>/dev/null || echo \"  ‚ö†Ô∏è Config not found\"\n",
        "\n",
        "print(\"\\n‚úÖ Backup complete!\")\n",
        "print(f\"Files saved to: {backup_dir}\")"
      ],
      "metadata": {
        "id": "save_to_drive"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéâ Congratulations!\n",
        "\n",
        "You've successfully completed the RAFT fine-tuning pipeline!\n",
        "\n",
        "### What you've accomplished:\n",
        "\n",
        "‚úÖ Installed all dependencies  \n",
        "‚úÖ Loaded MSRS Story-QA dataset  \n",
        "‚úÖ Built vector search index  \n",
        "‚úÖ Generated RAFT training data with CoT  \n",
        "‚úÖ Fine-tuned Qwen3-4B with QLoRA  \n",
        "‚úÖ Evaluated model performance  \n",
        "‚úÖ Created interactive demo  \n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. **Increase dataset size** - Train on 100+ examples for better performance\n",
        "2. **Tune hyperparameters** - Adjust learning rate, batch size, epochs\n",
        "3. **Try different models** - Experiment with other base models\n",
        "4. **Compare baselines** - Test against 0-shot and standard SFT\n",
        "5. **Deploy the model** - Use for production QA tasks\n",
        "\n",
        "### Resources:\n",
        "\n",
        "- üìö [RAFT Paper](https://arxiv.org/abs/2403.10131)\n",
        "- üîß [GitHub Repository](https://github.com/limcheekin/MSRS-RAFT)\n",
        "- üìñ [Unsloth Documentation](https://docs.unsloth.ai/)\n",
        "- üí¨ [MSRS Dataset](https://huggingface.co/datasets/yale-nlp/MSRS)\n",
        "\n",
        "### Need Help?\n",
        "\n",
        "- Check the [GitHub Issues](https://github.com/limcheekin/MSRS-RAFT/issues)\n",
        "- Review the [COLAB_GUIDE.md](https://github.com/limcheekin/MSRS-RAFT/blob/main/COLAB_GUIDE.md)\n",
        "- Run the troubleshooting cell above\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Training! üöÄ**"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}